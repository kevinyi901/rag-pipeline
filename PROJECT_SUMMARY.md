# RAG Pipeline - Project Summary

## ğŸ¯ What You Have

A **production-ready, Docker-containerized RAG pipeline** for legal document retrieval that runs on AWS EC2 with GPU support.

---

## ğŸ“¦ Complete File List (18 files)

### Core Python Files (8)
```
âœ“ config.py              - Configuration & environment variables
âœ“ models.py              - LLM & reranker initialization  
âœ“ filters.py             - Filter processing utilities
âœ“ retrieval.py           - Pinecone retrieval (baseline & hybrid)
âœ“ llm_generation.py      - LLM response generation
âœ“ utils.py               - CSV export & printing utilities
âœ“ pipeline.py            - Main pipeline orchestration
âœ“ main.py                - Entry point with CLI
```

### Docker Files (6)
```
âœ“ Dockerfile             - Container image definition
âœ“ docker-compose.yml     - Container orchestration
âœ“ .dockerignore          - Build optimization
âœ“ build.sh               - Build automation script
âœ“ run.sh                 - Run automation script  
âœ“ .env.example           - Environment template
```

### Documentation (4)
```
âœ“ README.md                    - Complete documentation
âœ“ EC2_SETUP.md                 - Detailed EC2 guide
âœ“ QUICKSTART.md                - 5-minute deployment
âœ“ DEPLOYMENT_CHECKLIST.md      - Step-by-step checklist
```

### Configuration Files (3)
```
âœ“ requirements.txt       - Python dependencies
âœ“ example_query.json     - Example query format
âœ“ .gitignore            - Git exclusions
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AWS EC2 GPU Instance                  â”‚
â”‚                         (g4dn.xlarge)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Docker Container                          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚         RAG Pipeline Application                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚   LLaMA 3.1  â”‚    â”‚  Reranker    â”‚          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚   8B Model   â”‚    â”‚   Model      â”‚          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚           â”‚                  â”‚                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                    â”‚                             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â”‚   Pipeline Core     â”‚                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â”‚  â€¢ Retrieval        â”‚                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â”‚  â€¢ Filtering        â”‚                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â”‚  â€¢ Generation       â”‚                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                    â”‚                             â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                       â”‚                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                     â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                 â”‚  outputs/ dir   â”‚                           â”‚
â”‚                 â”‚  (Volume Mount) â”‚                           â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Pinecone Vector DB  â”‚
              â”‚  (Cloud - External)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Deployment Flow

```
1. GitHub Push
   â”‚
   â–¼
2. Clone on EC2
   â”‚
   â–¼
3. Set .env Variables
   â”‚
   â–¼
4. Build Docker Image (./build.sh)
   â”‚
   â–¼
5. Run Container (./run.sh)
   â”‚
   â–¼
6. Models Download (First run only)
   â”‚
   â–¼
7. Pipeline Ready! âœ“
```

---

## ğŸ® Usage Modes

### Mode 1: Baseline Search (Dense Embedding Only)
```bash
docker compose up
# or
python main.py --mode baseline --example
```
**Output**: `baseline_retrieval_output.csv`

### Mode 2: Hybrid Search (Dense + Sparse + Reranking)
```bash
docker run --gpus all --env-file .env \
  -v $(pwd)/outputs:/app/outputs \
  rag-pipeline:latest \
  python3 main.py --mode hybrid --example
```
**Output**: `hybrid_retrieval_output.csv`

### Mode 3: Filter-Only Search
```bash
# Set query to empty string in JSON
python main.py --mode hybrid --json queries/filter_only.json
```
**Output**: `hybrid_filter_only_output.csv`

---

## ğŸ“Š Input/Output

### Input
```json
{
  "query": "Are dogs allowed in public parks?",
  "filters": {
    "locations": [
      {"state": "ca", "county": ["alameda-county"]}
    ],
    "penalty": "Y"
  }
}
```

### Output (CSV)
| Column | Description |
|--------|-------------|
| id | Document ID |
| score | Similarity score |
| rerank_score | Reranker score (hybrid mode) |
| state | State code |
| county | County name |
| section | Legal section reference |
| chunk_text | Full text of law snippet |
| penalty, obligation, etc. | Binary tags |
| fk_grade, fre, wc | Readability metrics |

**Plus**: LLM-generated natural language summary

---

## ğŸ’° Cost Breakdown

### EC2 Costs (g4dn.xlarge in us-east-1)
- **On-Demand**: ~$0.526/hour
- **24/7 Monthly**: ~$379.22
- **8 hours/day**: ~$126.41/month
- **Spot Instance**: 60-70% cheaper!

### API Costs
- **Pinecone**: Varies by usage (check your plan)
- **Hugging Face**: Free (you host the model)

**Cost-Saving Tips:**
1. Stop instance when not in use
2. Use Spot instances for batch jobs
3. Consider reserved instances for long-term

---

## ğŸ”§ Key Features

- âœ… **Modular Design**: Easy to modify and extend
- âœ… **Docker-First**: Consistent environment everywhere
- âœ… **GPU Optimized**: 4-bit quantization for efficiency
- âœ… **Production Ready**: Error handling, logging, validation
- âœ… **Flexible Filtering**: 10+ filter types supported
- âœ… **CSV Export**: Ready for Streamlit or other frontends
- âœ… **Two Search Modes**: Baseline and Hybrid with reranking
- âœ… **Batch Processing**: Process multiple queries in queue
- âœ… **Easy Deployment**: One command build and run

---

## ğŸ“š Documentation Guide

**Start here:**
1. ğŸ“– **QUICKSTART.md** - Get running in 5 minutes
2. ğŸ“‹ **DEPLOYMENT_CHECKLIST.md** - Track your progress
3. ğŸ“˜ **EC2_SETUP.md** - Detailed setup instructions
4. ğŸ“• **README.md** - Complete reference

---

## ğŸ”Œ Integration with Streamlit

Your pipeline outputs CSV files that can be directly consumed by Streamlit:

```python
# In your Streamlit app
import subprocess
import pandas as pd

def run_rag_query(query, filters):
    # Option 1: Call via API (TODO: add API layer)
    # Option 2: Run Docker container
    subprocess.run([
        "docker", "run", "--gpus", "all",
        "--env-file", ".env",
        "-v", "$(pwd)/outputs:/app/outputs",
        "rag-pipeline:latest",
        "python3", "main.py", "--mode", "hybrid",
        "--query", query
    ])
    
    # Read results
    df = pd.read_csv("outputs/hybrid_retrieval_output.csv")
    return df

# In Streamlit
df = run_rag_query(user_query, user_filters)
st.dataframe(df)
```

---

## ğŸ¯ Next Steps

1. **Deploy to EC2** - Follow QUICKSTART.md
2. **Test with Your Data** - Run example queries
3. **Integrate with Frontend** - Connect to Streamlit
4. **Scale as Needed** - Add more instances or move to ECS
5. **Monitor Costs** - Set up billing alerts

---

## âœ… What Makes This Production-Ready

- âœ… Environment variable configuration
- âœ… Error handling throughout
- âœ… Docker containerization
- âœ… GPU optimization
- âœ… Modular, testable code
- âœ… Comprehensive documentation
- âœ… Deployment automation
- âœ… Volume mounts for persistence
- âœ… Multiple usage modes
- âœ… CSV export for integration

---

## ğŸ¤ Support

**For Issues:**
1. Check troubleshooting in EC2_SETUP.md
2. Review container logs: `docker compose logs -f`
3. Verify GPU access: `nvidia-smi`
4. Check API keys in .env

**Resources:**
- AWS EC2 Documentation
- Docker Documentation  
- Pinecone Documentation
- Hugging Face Hub

---

## ğŸ“ Version Info

- **Pipeline Version**: 1.0.0
- **LLM Model**: meta-llama/Llama-3.1-8B-Instruct
- **Embedding**: Pinecone llama-text-embed-v2 + sparse
- **Reranker**: cross-encoder/ms-marco-MiniLM-L-6-v2
- **Python**: 3.10+
- **CUDA**: 12.1+
- **Docker**: 20.10+

---

**Ready to deploy? Start with QUICKSTART.md! ğŸš€**
